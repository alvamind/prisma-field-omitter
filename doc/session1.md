zenstack/packages/schema/src/plugins/enhancer/enhance
/index.ts

import { ReadonlyDeep } from '@prisma/generator-helper';
import { DELEGATE_AUX_RELATION_PREFIX } from '@zenstackhq/runtime';
import {
    PluginError,
    getAttribute,
    getAttributeArg,
    getAuthDecl,
    getDataModelAndTypeDefs,
    getDataModels,
    getForeignKeyFields,
    getLiteral,
    getRelationField,
    hasAttribute,
    isDelegateModel,
    isDiscriminatorField,
    normalizedRelative,
    saveSourceFile,
    type PluginOptions,
} from '@zenstackhq/sdk';
import {
    DataModel,
    DataModelField,
    ReferenceExpr,
    isArrayExpr,
    isDataModel,
    isGeneratorDecl,
    isTypeDef,
    type Model,
} from '@zenstackhq/sdk/ast';
import { getDMMF, getPrismaClientImportSpec, getPrismaVersion, type DMMF } from '@zenstackhq/sdk/prisma';
import fs from 'fs';
import path from 'path';
import semver from 'semver';
import {
    FunctionDeclarationStructure,
    InterfaceDeclaration,
    ModuleDeclaration,
    Node,
    Project,
    SourceFile,
    SyntaxKind,
    TypeAliasDeclaration,
    VariableStatement,
} from 'ts-morph';
import { upperCaseFirst } from 'upper-case-first';
import { name } from '..';
import { getConcreteModels, getDiscriminatorField } from '../../../utils/ast-utils';
import { execPackage } from '../../../utils/exec-utils';
import { CorePlugins, getPluginCustomOutputFolder } from '../../plugin-utils';
import { trackPrismaSchemaError } from '../../prisma';
import { PrismaSchemaGenerator } from '../../prisma/schema-generator';
import { isDefaultWithAuth } from '../enhancer-utils';
import { generateAuthType } from './auth-type-generator';
import { generateCheckerType } from './checker-type-generator';
import { generateTypeDefType } from './model-typedef-generator';

// information of delegate models and their sub models
type DelegateInfo = [DataModel, DataModel[]][];

const LOGICAL_CLIENT_GENERATION_PATH = './.logical-prisma-client';

export class EnhancerGenerator {
    // regex for matching "ModelCreateXXXInput" and "ModelUncheckedCreateXXXInput" type
    // names for models that use `auth()` in `@default` attribute
    private readonly modelsWithAuthInDefaultCreateInputPattern: RegExp;

    constructor(
        private readonly model: Model,
        private readonly options: PluginOptions,
        private readonly project: Project,
        private readonly outDir: string
    ) {
        const modelsWithAuthInDefault = this.model.declarations.filter(
            (d): d is DataModel => isDataModel(d) && d.fields.some((f) => f.attributes.some(isDefaultWithAuth))
        );
        this.modelsWithAuthInDefaultCreateInputPattern = new RegExp(
            `^(${modelsWithAuthInDefault.map((m) => m.name).join('|')})(Unchecked)?Create.*?Input$`
        );
    }

    async generate(): Promise<{ dmmf: DMMF.Document | undefined; newPrismaClientDtsPath: string | undefined }> {
        let dmmf: DMMF.Document | undefined;

        const prismaImport = getPrismaClientImportSpec(this.outDir, this.options);
        let prismaTypesFixed = false;
        let resultPrismaImport = prismaImport;

        if (this.needsLogicalClient) {
            prismaTypesFixed = true;
            resultPrismaImport = `${LOGICAL_CLIENT_GENERATION_PATH}/index-fixed`;
            const result = await this.generateLogicalPrisma();
            dmmf = result.dmmf;
        }

        // reexport PrismaClient types (original or fixed)
        const prismaDts = this.project.createSourceFile(
            path.join(this.outDir, 'models.d.ts'),
            `export type * from '${resultPrismaImport}';`,
            { overwrite: true }
        );
        await prismaDts.save();

        const authDecl = getAuthDecl(getDataModelAndTypeDefs(this.model));
        const authTypes = authDecl ? generateAuthType(this.model, authDecl) : '';
        const authTypeParam = authDecl ? `auth.${authDecl.name}` : 'AuthUser';

        const checkerTypes = this.generatePermissionChecker ? generateCheckerType(this.model) : '';

        for (const target of ['node', 'edge']) {
            // generate separate `enhance()` for node and edge runtime
            const outFile = target === 'node' ? 'enhance.ts' : 'enhance-edge.ts';
            const enhanceTs = this.project.createSourceFile(
                path.join(this.outDir, outFile),
                `/* eslint-disable */
import { type EnhancementContext, type EnhancementOptions, type ZodSchemas, type AuthUser } from '@zenstackhq/runtime';
import { createEnhancement } from '@zenstackhq/runtime/enhancements/${target}';
import modelMeta from './model-meta';
import policy from './policy';
${
    this.options.withZodSchemas
        ? `import * as zodSchemas from '${this.getZodImport()}';`
        : 'const zodSchemas = undefined;'
}

${
    prismaTypesFixed
        ? this.createLogicalPrismaImports(prismaImport, resultPrismaImport)
        : this.createSimplePrismaImports(prismaImport)
}

${authTypes}

${checkerTypes}

${
    prismaTypesFixed
        ? this.createLogicalPrismaEnhanceFunction(authTypeParam)
        : this.createSimplePrismaEnhanceFunction(authTypeParam)
}
    `,
                { overwrite: true }
            );

            this.saveSourceFile(enhanceTs);
        }

        return {
            dmmf,
            newPrismaClientDtsPath: prismaTypesFixed
                ? path.resolve(this.outDir, LOGICAL_CLIENT_GENERATION_PATH, 'index-fixed.d.ts')
                : undefined,
        };
    }

    private getZodImport() {
        const zodCustomOutput = getPluginCustomOutputFolder(this.model, CorePlugins.Zod);

        if (!this.options.output && !zodCustomOutput) {
            // neither zod or me (enhancer) have custom output, use the default
            return './zod';
        }

        if (!zodCustomOutput) {
            // I have a custom output, but zod doesn't, import from runtime
            return '@zenstackhq/runtime/zod';
        }

        if (!this.options.output) {
            // I don't have a custom output, but zod has, CLI will still generate
            // a copy into the default output, so we can still import from there
            return './zod';
        }

        // both zod and me have custom output, resolve to relative path and import
        const schemaDir = path.dirname(this.options.schemaPath);
        const zodAbsPath = path.isAbsolute(zodCustomOutput)
            ? zodCustomOutput
            : path.resolve(schemaDir, zodCustomOutput);
        return normalizedRelative(this.outDir, zodAbsPath);
    }

    private createSimplePrismaImports(prismaImport: string) {
        return `import { Prisma, type PrismaClient } from '${prismaImport}';
import type * as _P from '${prismaImport}';
export type { PrismaClient };
        `;
    }

    private createSimplePrismaEnhanceFunction(authTypeParam: string) {
        const returnType = `DbClient${this.generatePermissionChecker ? ' & ModelCheckers' : ''}`;
        return `
export function enhance<DbClient extends object>(prisma: DbClient, context?: EnhancementContext<${authTypeParam}>, options?: EnhancementOptions): ${returnType} {
    return createEnhancement(prisma, {
        modelMeta,
        policy,
        zodSchemas: zodSchemas as unknown as (ZodSchemas | undefined),
        prismaModule: Prisma,
        ...options
    }, context) as ${returnType};
}
            `;
    }

    private createLogicalPrismaImports(prismaImport: string, prismaClientImport: string) {
        return `import { Prisma as _Prisma, PrismaClient as _PrismaClient } from '${prismaImport}';
import type { InternalArgs, DynamicClientExtensionThis } from '${prismaImport}/runtime/library';
import type * as _P from '${prismaClientImport}';
import type { Prisma, PrismaClient } from '${prismaClientImport}';
export type { PrismaClient };
`;
    }

    private createLogicalPrismaEnhanceFunction(authTypeParam: string) {
        const prismaVersion = getPrismaVersion();

        // Prisma 5.16.0 introduced a new generic parameter to `DynamicClientExtensionThis`
        const hasClientOptions = prismaVersion && semver.gte(prismaVersion, '5.16.0');

        return `
// overload for plain PrismaClient
export function enhance<ExtArgs extends Record<string, any> & InternalArgs>(
    prisma: _PrismaClient<any, any, ExtArgs>,
    context?: EnhancementContext<${authTypeParam}>, options?: EnhancementOptions): PrismaClient${
            this.generatePermissionChecker ? ' & ModelCheckers' : ''
        };

// overload for extended PrismaClient
export function enhance<ExtArgs extends Record<string, any> & InternalArgs${hasClientOptions ? ', ClientOptions' : ''}>(
    prisma: DynamicClientExtensionThis<_Prisma.TypeMap<ExtArgs>, _Prisma.TypeMapCb, ExtArgs${
        hasClientOptions ? ', ClientOptions' : ''
    }>,
    context?: EnhancementContext<${authTypeParam}>, options?: EnhancementOptions): DynamicClientExtensionThis<Prisma.TypeMap<ExtArgs>, Prisma.TypeMapCb, ExtArgs${
            hasClientOptions ? ', ClientOptions' : ''
        }>${this.generatePermissionChecker ? ' & ModelCheckers' : ''};

export function enhance(prisma: any, context?: EnhancementContext<${authTypeParam}>, options?: EnhancementOptions): any {
    return createEnhancement(prisma, {
        modelMeta,
        policy,
        zodSchemas: zodSchemas as unknown as (ZodSchemas | undefined),
        prismaModule: _Prisma,
        ...options
    }, context);
}
`;
    }

    private get needsLogicalClient() {
        return this.hasDelegateModel(this.model) || this.hasAuthInDefault(this.model) || this.hasTypeDef(this.model);
    }

    private hasDelegateModel(model: Model) {
        const dataModels = getDataModels(model);
        return dataModels.some(
            (dm) => isDelegateModel(dm) && dataModels.some((sub) => sub.superTypes.some((base) => base.ref === dm))
        );
    }

    private hasAuthInDefault(model: Model) {
        return getDataModels(model).some((dm) =>
            dm.fields.some((f) => f.attributes.some((attr) => isDefaultWithAuth(attr)))
        );
    }

    private hasTypeDef(model: Model) {
        return model.declarations.some(isTypeDef);
    }

    private async generateLogicalPrisma() {
        const prismaGenerator = new PrismaSchemaGenerator(this.model);

        // dir of the zmodel file
        const zmodelDir = path.dirname(this.options.schemaPath);

        // generate a temp logical prisma schema in zmodel's dir
        const logicalPrismaFile = path.join(zmodelDir, `logical-${Date.now()}.prisma`);

        // calculate a relative output path to output the logical prisma client into enhancer's output dir
        const prismaClientOutDir = path.join(path.relative(zmodelDir, this.outDir), LOGICAL_CLIENT_GENERATION_PATH);
        await prismaGenerator.generate({
            provider: '@internal', // doesn't matter
            schemaPath: this.options.schemaPath,
            output: logicalPrismaFile,
            overrideClientGenerationPath: prismaClientOutDir,
            mode: 'logical',
            customAttributesAsComments: true,
        });

        // generate the prisma client

        // only run prisma client generator for the logical schema
        const prismaClientGeneratorName = this.getPrismaClientGeneratorName(this.model);
        let generateCmd = `prisma generate --schema "${logicalPrismaFile}" --generator=${prismaClientGeneratorName}`;

        const prismaVersion = getPrismaVersion();
        if (!prismaVersion || semver.gte(prismaVersion, '5.2.0')) {
            // add --no-engine to reduce generation size if the prisma version supports
            generateCmd += ' --no-engine';
        }

        try {
            // run 'prisma generate'
            await execPackage(generateCmd, { stdio: 'ignore' });
        } catch {
            await trackPrismaSchemaError(logicalPrismaFile);
            try {
                // run 'prisma generate' again with output to the console
                await execPackage(generateCmd);
            } catch {
                // noop
            }
            throw new PluginError(name, `Failed to run "prisma generate" on logical schema: ${logicalPrismaFile}`);
        }

        // make a bunch of typing fixes to the generated prisma client
        await this.processClientTypes(path.join(this.outDir, LOGICAL_CLIENT_GENERATION_PATH));

        // get the dmmf of the logical prisma schema
        const dmmf = await this.getLogicalDMMF(logicalPrismaFile);

        try {
            // clean up temp schema
            if (fs.existsSync(logicalPrismaFile)) {
                fs.rmSync(logicalPrismaFile);
            }
        } catch {
            // ignore errors
        }

        return {
            prismaSchema: logicalPrismaFile,
            // load the dmmf of the logical prisma schema
            dmmf,
        };
    }

    private async getLogicalDMMF(logicalPrismaFile: string) {
        const dmmf = await getDMMF({ datamodel: fs.readFileSync(logicalPrismaFile, { encoding: 'utf-8' }) });

        // make necessary fixes

        // fields that use `auth()` in `@default` are not handled by Prisma so in the DMMF
        // they may be incorrectly represented as required, we need to fix that for input types
        // also, if a FK field is of such case, its corresponding relation field should be optional
        const createInputPattern = new RegExp(`^(.+?)(Unchecked)?Create.*Input$`);
        for (const inputType of dmmf.schema.inputObjectTypes.prisma) {
            const match = inputType.name.match(createInputPattern);
            const modelName = match?.[1];
            if (modelName) {
                const dataModel = this.model.declarations.find(
                    (d): d is DataModel => isDataModel(d) && d.name === modelName
                );
                if (dataModel) {
                    for (const field of inputType.fields) {
                        if (field.isRequired && this.shouldBeOptional(field, dataModel)) {
                            // eslint-disable-next-line @typescript-eslint/no-explicit-any
                            (field as any).isRequired = false;
                        }
                    }
                }
            }
        }
        return dmmf;
    }

    private shouldBeOptional(field: ReadonlyDeep<DMMF.SchemaArg>, dataModel: DataModel) {
        const dmField = dataModel.fields.find((f) => f.name === field.name);
        if (!dmField) {
            return false;
        }

        if (hasAttribute(dmField, '@default')) {
            return true;
        }

        if (isDataModel(dmField.type.reference?.ref)) {
            // if FK field should be optional, the relation field should too
            const fkFields = getForeignKeyFields(dmField);
            if (fkFields.length > 0 && fkFields.every((f) => hasAttribute(f, '@default'))) {
                return true;
            }
        }

        return false;
    }

    private getPrismaClientGeneratorName(model: Model) {
        for (const generator of model.declarations.filter(isGeneratorDecl)) {
            if (
                generator.fields.some(
                    (f) => f.name === 'provider' && getLiteral<string>(f.value) === 'prisma-client-js'
                )
            ) {
                return generator.name;
            }
        }
        throw new PluginError(name, `Cannot find prisma-client-js generator in the schema`);
    }

    private async processClientTypes(prismaClientDir: string) {
        // make necessary updates to the generated `index.d.ts` file and save it as `index-fixed.d.ts`
        const project = new Project();
        const sf = project.addSourceFileAtPath(path.join(prismaClientDir, 'index.d.ts'));

        // build a map of delegate models and their sub models
        const delegateInfo: DelegateInfo = [];
        this.model.declarations
            .filter((d): d is DataModel => isDelegateModel(d))
            .forEach((dm) => {
                const concreteModels = getConcreteModels(dm);
                if (concreteModels.length > 0) {
                    delegateInfo.push([dm, concreteModels]);
                }
            });

        // transform index.d.ts and save it into a new file (better perf than in-line editing)

        const sfNew = project.createSourceFile(path.join(prismaClientDir, 'index-fixed.d.ts'), undefined, {
            overwrite: true,
        });

        this.transformPrismaTypes(sf, sfNew, delegateInfo);

        this.generateExtraTypes(sfNew);

        sfNew.formatText();
        await sfNew.save();
    }

    private transformPrismaTypes(sf: SourceFile, sfNew: SourceFile, delegateInfo: DelegateInfo) {
        // copy toplevel imports
        sfNew.addImportDeclarations(sf.getImportDeclarations().map((n) => n.getStructure()));

        // copy toplevel import equals
        sfNew.addStatements(sf.getChildrenOfKind(SyntaxKind.ImportEqualsDeclaration).map((n) => n.getFullText()));

        // copy toplevel exports
        sfNew.addExportAssignments(sf.getExportAssignments().map((n) => n.getStructure()));

        // copy toplevel type aliases
        sfNew.addTypeAliases(sf.getTypeAliases().map((n) => n.getStructure()));

        // copy toplevel classes
        sfNew.addClasses(sf.getClasses().map((n) => n.getStructure()));

        // copy toplevel variables
        sfNew.addVariableStatements(sf.getVariableStatements().map((n) => n.getStructure()));

        // copy toplevel namespaces except for `Prisma`
        sfNew.addModules(
            sf
                .getModules()
                .filter((n) => n.getName() !== 'Prisma')
                .map((n) => n.getStructure())
        );

        // transform the `Prisma` namespace
        const prismaModule = sf.getModuleOrThrow('Prisma');
        const newPrismaModule = sfNew.addModule({ name: 'Prisma', isExported: true });
        this.transformPrismaModule(prismaModule, newPrismaModule, delegateInfo);
    }

    private transformPrismaModule(
        prismaModule: ModuleDeclaration,
        newPrismaModule: ModuleDeclaration,
        delegateInfo: DelegateInfo
    ) {
        // module block is the direct container of declarations inside a namespace
        const moduleBlock = prismaModule.getFirstChildByKindOrThrow(SyntaxKind.ModuleBlock);

        // most of the toplevel constructs should be copied over
        // here we use ts-morph batch operations for optimal performance

        // copy imports
        newPrismaModule.addStatements(
            moduleBlock.getChildrenOfKind(SyntaxKind.ImportEqualsDeclaration).map((n) => n.getFullText())
        );

        // copy classes
        newPrismaModule.addClasses(moduleBlock.getClasses().map((n) => n.getStructure()));

        // copy functions
        newPrismaModule.addFunctions(
            moduleBlock.getFunctions().map((n) => n.getStructure() as FunctionDeclarationStructure)
        );

        // copy nested namespaces
        newPrismaModule.addModules(moduleBlock.getModules().map((n) => n.getStructure()));

        // transform variables
        const newVariables = moduleBlock
            .getVariableStatements()
            .map((variable) => this.transformVariableStatement(variable));
        newPrismaModule.addVariableStatements(newVariables);

        // transform interfaces
        const newInterfaces = moduleBlock.getInterfaces().map((iface) => this.transformInterface(iface, delegateInfo));
        newPrismaModule.addInterfaces(newInterfaces);

        // transform type aliases
        const newTypeAliases = moduleBlock
            .getTypeAliases()
            .map((typeAlias) => this.transformTypeAlias(typeAlias, delegateInfo));
        newPrismaModule.addTypeAliases(newTypeAliases);
    }

    private transformVariableStatement(variable: VariableStatement) {
        const structure = variable.getStructure();

        // remove `delegate_aux_*` fields from the variable's typing
        const auxFields = this.findAuxDecls(variable);
        if (auxFields.length > 0) {
            structure.declarations.forEach((variable) => {
                if (variable.type) {
                    let source = variable.type.toString();
                    auxFields.forEach((f) => {
                        source = this.removeFromSource(source, f.getText());
                    });
                    variable.type = source;
                }
            });
        }

        return structure;
    }

    private transformInterface(iface: InterfaceDeclaration, delegateInfo: DelegateInfo) {
        const structure = iface.getStructure();

        // filter out aux fields
        structure.properties = structure.properties?.filter((p) => !p.name.startsWith(DELEGATE_AUX_RELATION_PREFIX));

        // filter out aux methods
        structure.methods = structure.methods?.filter((m) => !m.name.startsWith(DELEGATE_AUX_RELATION_PREFIX));

        if (delegateInfo.some(([delegate]) => `${delegate.name}Delegate` === iface.getName())) {
            // delegate models cannot be created directly, remove create/createMany/upsert
            structure.methods = structure.methods?.filter(
                (m) => !['create', 'createMany', 'createManyAndReturn', 'upsert'].includes(m.name)
            );
        }

        return structure;
    }

    private transformTypeAlias(typeAlias: TypeAliasDeclaration, delegateInfo: DelegateInfo) {
        const structure = typeAlias.getStructure();
        let source = structure.type as string;

        // remove aux fields
        source = this.removeAuxFieldsFromTypeAlias(typeAlias, source);

        // remove discriminator field from concrete input types
        source = this.removeDiscriminatorFromConcreteInput(typeAlias, delegateInfo, source);

        // remove create/connectOrCreate/upsert fields from delegate's input types
        source = this.removeCreateFromDelegateInput(typeAlias, delegateInfo, source);

        // remove delegate fields from nested mutation input types
        source = this.removeDelegateFieldsFromNestedMutationInput(typeAlias, delegateInfo, source);

        // fix delegate payload union type
        source = this.fixDelegatePayloadType(typeAlias, delegateInfo, source);

        // fix fk and relation fields related to using `auth()` in `@default`
        source = this.fixDefaultAuthType(typeAlias, source);

        // fix json field type
        source = this.fixJsonFieldType(typeAlias, source);

        structure.type = source;
        return structure;
    }

    private fixDelegatePayloadType(typeAlias: TypeAliasDeclaration, delegateInfo: DelegateInfo, source: string) {
        // change the type of `$<DelegateModel>Payload` type of delegate model to a union of concrete types
        const typeName = typeAlias.getName();
        const payloadRecord = delegateInfo.find(([delegate]) => `$${delegate.name}Payload` === typeName);
        if (payloadRecord) {
            const discriminatorDecl = getDiscriminatorField(payloadRecord[0]);
            if (discriminatorDecl) {
                source = `${payloadRecord[1]
                    .map(
                        (concrete) =>
                            `($${concrete.name}Payload<ExtArgs> & { scalars: { ${discriminatorDecl.name}: '${concrete.name}' } })`
                    )
                    .join(' | ')}`;
            }
        }
        return source;
    }

    private removeCreateFromDelegateInput(typeAlias: TypeAliasDeclaration, delegateInfo: DelegateInfo, source: string) {
        // remove create/connectOrCreate/upsert fields from delegate's input types because
        // delegate models cannot be created directly
        const typeName = typeAlias.getName();
        const delegateModelNames = delegateInfo.map(([delegate]) => delegate.name);
        const delegateCreateUpdateInputRegex = new RegExp(
            `^(${delegateModelNames.join('|')})(Unchecked)?(Create|Update).*Input$`
        );
        if (delegateCreateUpdateInputRegex.test(typeName)) {
            const toRemove = typeAlias
                .getDescendantsOfKind(SyntaxKind.PropertySignature)
                .filter((p) => ['create', 'createMany', 'connectOrCreate', 'upsert'].includes(p.getName()));
            toRemove.forEach((r) => {
                this.removeFromSource(source, r.getText());
            });
        }
        return source;
    }

    private removeDiscriminatorFromConcreteInput(
        typeAlias: TypeAliasDeclaration,
        delegateInfo: DelegateInfo,
        source: string
    ) {
        // remove discriminator field from the create/update input because discriminator cannot be set directly
        const typeName = typeAlias.getName();

        const delegateModelNames = delegateInfo.map(([delegate]) => delegate.name);
        const concreteModelNames = delegateInfo
            .map(([_, concretes]) => concretes.flatMap((c) => c.name))
            .flatMap((name) => name);
        const allModelNames = [...new Set([...delegateModelNames, ...concreteModelNames])];
        const concreteCreateUpdateInputRegex = new RegExp(
            `^(${allModelNames.join('|')})(Unchecked)?(Create|Update).*Input$`
        );

        const match = typeName.match(concreteCreateUpdateInputRegex);
        if (match) {
            const modelName = match[1];
            const dataModel = this.model.declarations.find(
                (d): d is DataModel => isDataModel(d) && d.name === modelName
            );

            if (!dataModel) {
                return source;
            }

            for (const field of dataModel.fields) {
                if (isDiscriminatorField(field)) {
                    const fieldDef = this.findNamedProperty(typeAlias, field.name);
                    if (fieldDef) {
                        source = this.removeFromSource(source, fieldDef.getText());
                    }
                }
            }
        }
        return source;
    }

    private removeAuxFieldsFromTypeAlias(typeAlias: TypeAliasDeclaration, source: string) {
        // remove `delegate_aux_*` fields from the type alias
        const auxDecls = this.findAuxDecls(typeAlias);
        if (auxDecls.length > 0) {
            auxDecls.forEach((d) => {
                source = this.removeFromSource(source, d.getText());
            });
        }
        return source;
    }

    private readonly CreateUpdateWithoutDelegateRelationRegex = new RegExp(
        `(.+)(Create|Update)Without${upperCaseFirst(DELEGATE_AUX_RELATION_PREFIX)}_(.+)Input`
    );

    private removeDelegateFieldsFromNestedMutationInput(
        typeAlias: TypeAliasDeclaration,
        _delegateInfo: DelegateInfo,
        source: string
    ) {
        const name = typeAlias.getName();

        // remove delegate model fields (and corresponding fk fields) from
        // create/update input types nested inside concrete models

        const match = name.match(this.CreateUpdateWithoutDelegateRelationRegex);
        if (!match) {
            return source;
        }

        const nameTuple = match[3]; // [modelName]_[relationFieldName]_[concreteModelName]
        const [modelName, relationFieldName, _] = nameTuple.split('_');

        const fieldDef = this.findNamedProperty(typeAlias, relationFieldName);
        if (fieldDef) {
            // remove relation field of delegate type, e.g., `asset`
            source = this.removeFromSource(source, fieldDef.getText());
        }

        // remove fk fields related to the delegate type relation, e.g., `assetId`

        const relationModel = this.model.declarations.find(
            (d): d is DataModel => isDataModel(d) && d.name === modelName
        );

        if (!relationModel) {
            return source;
        }

        const relationField = relationModel.fields.find((f) => f.name === relationFieldName);
        if (!relationField) {
            return source;
        }

        const relAttr = getAttribute(relationField, '@relation');
        if (!relAttr) {
            return source;
        }

        const fieldsArg = getAttributeArg(relAttr, 'fields');
        let fkFields: string[] = [];
        if (isArrayExpr(fieldsArg)) {
            fkFields = fieldsArg.items.map((e) => (e as ReferenceExpr).target.$refText);
        }

        fkFields.forEach((fkField) => {
            const fieldDef = this.findNamedProperty(typeAlias, fkField);
            if (fieldDef) {
                source = this.removeFromSource(source, fieldDef.getText());
            }
        });

        return source;
    }

    private fixDefaultAuthType(typeAlias: TypeAliasDeclaration, source: string) {
        const match = typeAlias.getName().match(this.modelsWithAuthInDefaultCreateInputPattern);
        if (!match) {
            return source;
        }

        const modelName = match[1];
        const dataModel = this.model.declarations.find((d): d is DataModel => isDataModel(d) && d.name === modelName);
        if (dataModel) {
            for (const fkField of dataModel.fields.filter((f) => f.attributes.some(isDefaultWithAuth))) {
                // change fk field to optional since it has a default
                source = source.replace(new RegExp(`^(\\s*${fkField.name}\\s*):`, 'm'), `$1?:`);

                const relationField = getRelationField(fkField);
                if (relationField) {
                    // change relation field to optional since its fk has a default
                    source = source.replace(new RegExp(`^(\\s*${relationField.name}\\s*):`, 'm'), `$1?:`);
                }
            }
        }
        return source;
    }

    private fixJsonFieldType(typeAlias: TypeAliasDeclaration, source: string) {
        const modelsWithTypeField = this.model.declarations.filter(
            (d): d is DataModel => isDataModel(d) && d.fields.some((f) => isTypeDef(f.type.reference?.ref))
        );
        const typeName = typeAlias.getName();

        const getTypedJsonFields = (model: DataModel) => {
            return model.fields.filter((f) => isTypeDef(f.type.reference?.ref));
        };

        const replacePrismaJson = (source: string, field: DataModelField) => {
            return source.replace(
                new RegExp(`(${field.name}\\??\\s*):[^\\n]+`),
                `$1: ${field.type.reference!.$refText}${field.type.array ? '[]' : ''}${
                    field.type.optional ? ' | null' : ''
                }`
            );
        };

        // fix "$[Model]Payload" type
        const payloadModelMatch = modelsWithTypeField.find((m) => `$${m.name}Payload` === typeName);
        if (payloadModelMatch) {
            const scalars = typeAlias
                .getDescendantsOfKind(SyntaxKind.PropertySignature)
                .find((p) => p.getName() === 'scalars');
            if (!scalars) {
                return source;
            }

            const fieldsToFix = getTypedJsonFields(payloadModelMatch);
            for (const field of fieldsToFix) {
                source = replacePrismaJson(source, field);
            }
        }

        // fix input/output types, "[Model]CreateInput", etc.
        const inputOutputModelMatch = modelsWithTypeField.find((m) => typeName.startsWith(m.name));
        if (inputOutputModelMatch) {
            const relevantTypePatterns = [
                'GroupByOutputType',
                '(Unchecked)?Create(\\S+?)?Input',
                '(Unchecked)?Update(\\S+?)?Input',
                'CreateManyInput',
                '(Unchecked)?UpdateMany(Mutation)?Input',
            ];
            const typeRegex = modelsWithTypeField.map(
                (m) => new RegExp(`^(${m.name})(${relevantTypePatterns.join('|')})$`)
            );
            if (typeRegex.some((r) => r.test(typeName))) {
                const fieldsToFix = getTypedJsonFields(inputOutputModelMatch);
                for (const field of fieldsToFix) {
                    source = replacePrismaJson(source, field);
                }
            }
        }

        return source;
    }

    private async generateExtraTypes(sf: SourceFile) {
        for (const decl of this.model.declarations) {
            if (isTypeDef(decl)) {
                generateTypeDefType(sf, decl);
            }
        }
    }

    private findNamedProperty(typeAlias: TypeAliasDeclaration, name: string) {
        return typeAlias.getFirstDescendant((d) => d.isKind(SyntaxKind.PropertySignature) && d.getName() === name);
    }

    private findAuxDecls(node: Node) {
        return node
            .getDescendantsOfKind(SyntaxKind.PropertySignature)
            .filter((n) => n.getName().startsWith(DELEGATE_AUX_RELATION_PREFIX));
    }

    private saveSourceFile(sf: SourceFile) {
        if (this.options.preserveTsFiles) {
            saveSourceFile(sf);
        }
    }

    private get generatePermissionChecker() {
        return this.options.generatePermissionChecker === true;
    }

    private removeFromSource(source: string, text: string) {
        source = source.replace(text, '');
        return this.trimEmptyLines(source);
    }

    private trimEmptyLines(source: string): string {
        return source.replace(/^\s*[\r\n]/gm, '');
    }
}

This code is part of a TypeScript code generator for enhancing Prisma client types. Here's a high-level explanation of its main functionality:

1. The `EnhancerGenerator` class is responsible for generating enhanced TypeScript types and client code based on a Prisma schema.

Key components:

1. Constructor & Main Generate Method:
```typescript
constructor(
    private readonly model: Model,
    private readonly options: PluginOptions,
    private readonly project: Project,
    private readonly outDir: string
) {
    // Initialize regex for models with auth in default values
}

async generate(): Promise<{ dmmf: DMMF.Document | undefined; newPrismaClientDtsPath: string | undefined }>
```

2. Logical Client Generation:
- Handles creation of a "logical" Prisma client for special cases like delegate models
- Generates modified TypeScript definitions with enhanced types

3. Type Transformations:
- Transforms Prisma types for:
  - Delegate models and their inheritance
  - Authentication-related fields
  - JSON fields
  - Discriminator fields
  - Nested mutation inputs

4. Key Features:
- Generates separate enhance() functions for Node.js and Edge runtimes
- Handles type transformations for auth and permissions
- Processes TypeScript definitions to add custom types
- Manages Prisma client type modifications

Example usage:

```typescript
const generator = new EnhancerGenerator(model, options, project, outputDir);
const { dmmf, newPrismaClientDtsPath } = await generator.generate();
```

The generator creates:
- Enhanced Prisma client types
- Permission checker types (optional)
- Auth-related types
- Modified type definitions for delegation and inheritance

The key functionality focuses on type safety and integration with Prisma while adding custom features like authentication and authorization.

Would you like me to explain any specific part in more detail?

```json prisma-field-omitter/package.json
{
  "name": "prisma-field-omitter",
  "version": "1.0.16",
  "description": "A utility to omit fields from Prisma queries",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": {
      "import": "./dist/index.js",
      "types": "./dist/index.d.ts"
    },
    "./cli": {
      "import": "./dist/cli.js"
    }
  },
  "bin": {
    "prisma-field-omitter": "./dist/cli.js"
  },
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "start": "bun run src/index.ts",
    "build": "tsc && chmod +x dist/cli.js",
    "clean": "clean"
  },
  "keywords": [
    "prisma",
    "utilities",
    "field-omitter"
  ],
  "author": "",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/alvamind/prisma-field-omitter.git"
  },
  "dependencies": {
    "alvamind": "^1.0.12",
    "alvamind-tools": "^1.0.23",
    "bun": "^1.2.2",
    "ts-morph": "^25.0.1"
  },
  "devDependencies": {
    "@types/bun": "^1.2.2",
    "bun-types": "latest",
    "typescript": "^5.7.3"
  },
  "peerDependencies": {
    "typescript": "^5.0.0"
  }
}
```

```json prisma-field-omitter/tsconfig.json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "lib": ["esnext", "dom"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "resolveJsonModule": true,
    "moduleResolution": "bundler",
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "types": ["bun-types"],
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitAny": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist", "test"]
}
```

prisma-field-omitter/src
```ts prisma-field-omitter/src/cli.ts
#!/usr/bin/env -S bun --bun

import type { ProcessingMode, ProcessingOptions } from "./types";
import { processorController } from "./modules/processor.controller";
import { configService } from "./modules/config.service";
import { loggerService } from "./modules/logger.service";

export async function run(options: ProcessingOptions) {
    if (!options.configPath) {
        throw new Error('--config option is required');
    }

    try {
        loggerService.loggerService.info(`ðŸ“– Reading config from: ${options.configPath}`);
        const config = await configService.configService.readConfig(options.configPath);
        if (!config) {
            throw new Error('Invalid configuration');
        }

        const stats = await processorController.process(config, options.mode || 'ast');
        return stats.filesProcessed > 0;
    } catch (error: any) {
        loggerService.loggerService.error(`Error during processing: ${error}`);
        // Ensure error is propagated
        process.exitCode = 1;
        throw error;
    }
}

// CLI execution handler
if (import.meta.main) { // Use import.meta.main for ESM
    const args = process.argv.slice(2);
    const configIndex = args.indexOf('--config');
    const modeIndex = args.indexOf('--mode');

    if (configIndex === -1 || !args[configIndex + 1]) {
        loggerService.loggerService.error('Error: --config option is required');
        process.exit(1);
    }

    const configPath = args[configIndex + 1];
    if (!configPath) {
        loggerService.loggerService.error('Error: --config value is missing');
        process.exit(1);
    }

    const options: ProcessingOptions = {
        configPath,
        verbose: args.includes('--verbose'),
        mode: (modeIndex !== -1 ? args[modeIndex + 1] : 'ast') as ProcessingMode
    };

    if (options.mode && !['ast', 'regex'].includes(options.mode)) {
        loggerService.loggerService.error('Error: --mode must be either "ast" or "regex"');
        process.exit(1);
    }

    run(options).catch((error) => {
        loggerService.loggerService.error(`Fatal error: ${error}`);
        process.exit(1);
    });
}
```

```ts prisma-field-omitter/src/exports.ts
import { processorController } from './modules/processor.controller';

// Get the controller methods from the Alvamind instance
const controller = processorController;

// Export the process function directly from the controller
export const process = controller.process;

// Re-export types
export type { Config } from './types';

// Export the full controller if needed
export { processorController };
```

```ts prisma-field-omitter/src/index.ts
import Alvamind from 'alvamind';
import { processorController } from './modules/processor.controller';
import { configService } from './modules/config.service';
import { loggerService } from './modules/logger.service';
import type { ProcessingOptions } from './types';

// Set up the Alvamind instance
Alvamind({ name: 'prisma-field-omitter' })
  .use(processorController)
  .use(configService)
  .use(loggerService)
  .derive(({ process: processOmit, configService: { readConfig }, loggerService: { info, success, error: logError } }) => ({
    run: async (options: ProcessingOptions) => {
      try {
        info('Starting prisma-field-omitter...');
        const config = await readConfig(options.configPath);
        const startTime = Date.now();

        await processOmit(config);

        const duration = ((Date.now() - startTime) / 1000).toFixed(2);
        success(`Processing completed successfully in ${duration}s!`);
      } catch (error) {
        logError('Error during processing:', error);
        process.exit(1);
      }
    }
  }));

// Instead of duplicating CLI argument processing here we export the run function
// and let cli.ts handle CLI execution.
export { run } from "./cli";
```

modules
```ts prisma-field-omitter/src/modules/ast.service.ts
import { Project, Node, PropertySignature } from "ts-morph";
import Alvamind from 'alvamind';
import { Glob } from "bun";
import type { Config } from '../types';
import { existsSync } from 'fs';
import { unlink } from 'fs/promises';
import { basename, join } from 'path';
import type { ProcessingStats } from './stats.service';

export const astService = Alvamind({ name: 'ast.service' })
  .decorate('astService', {
    createProject: () => new Project({
      tsConfigFilePath: "tsconfig.json",
      skipAddingFilesFromTsConfig: true,
    }),

    matchesPattern: (value: string, patterns: string[]): boolean => {
      return patterns.some(pattern => {
        const isNegated = pattern.startsWith('!');
        const actualPattern = isNegated ? pattern.slice(1) : pattern;
        const matches = new Glob(actualPattern).match(value);
        return isNegated ? !matches : matches;
      });
    },

    getTargetPatterns: (config: Config): string[] => {
      return config.hide.flatMap(rule =>
        Array.isArray(rule.target) ? rule.target :
          rule.target === 'all' ? ['*'] : [rule.target || '*']
      );
    },

    shouldProcessProperty: (
      prop: PropertySignature,
      typeName: string,
      config: Config
    ): boolean => {
      return config.hide.some(rule =>
        self.matchesPattern(typeName, self.getTargetPatterns(config)) &&
        self.matchesPattern(prop.getName(), Array.isArray(rule.field) ? rule.field : [rule.field])
      );
    },

    processProperties: (
      properties: PropertySignature[],
      typeName: string,
      config: Config,
      shouldProcessProperty: (prop: PropertySignature, typeName: string) => boolean
    ): number => {
      const toModify = properties.filter(prop =>
        !prop.wasForgotten() &&
        Node.isPropertySignature(prop) &&
        shouldProcessProperty(prop, typeName)
      );

      toModify.forEach(prop => {
        if (prop.wasForgotten()) return;
        const text = prop.getText();
        config.action === 'delete'
          ? prop.remove()
          : prop.replaceWithText(text.split('\n').map(line => `// ${line}`).join('\n'));
      });

      return toModify.length;
    },

    getInputFiles: async (patterns: string[]): Promise<string[]> => {
      const seenFiles = new Set<string>();
      const results: string[] = [];

      for (const pattern of patterns) {
        // Handle both absolute and relative paths
        const absolutePattern = pattern.startsWith('/')
          ? pattern
          : join(process.cwd(), pattern);

        // Check if the pattern is a direct file path
        if (existsSync(absolutePattern)) {
          if (!seenFiles.has(absolutePattern)) {
            seenFiles.add(absolutePattern);
            results.push(absolutePattern);
          }
          continue;
        }

        // Process glob pattern
        const globPattern = pattern.startsWith('/')
          ? pattern
          : join(process.cwd(), pattern);

        for await (const file of new Glob(globPattern).scan({ absolute: true })) {
          if (!seenFiles.has(file)) {
            seenFiles.has(file);
            results.push(file);
          }
        }
      }

      return results;
    },

    processNestedProperties: (
      node: Node,
      typeName: string,
      config: Config
    ): number => {
      let count = 0;
      if (node.wasForgotten()) return count;

      if (Node.isTypeLiteral(node)) {
        const properties = node.getProperties()
          .filter((p): p is PropertySignature => Node.isPropertySignature(p) && !p.wasForgotten());

        const toModify = properties.filter(prop =>
          !prop.wasForgotten() && self.shouldProcessProperty(prop, typeName, config)
        );

        toModify.forEach(prop => {
          if (prop.wasForgotten()) return;
          const text = prop.getText();
          if (config.action === "delete") {
            prop.remove();
          } else {
            prop.replaceWithText(text.split("\n").map(line => `// ${line}`).join("\n"));
          }
          count++;
        });

        properties.forEach(prop => {
          if (prop.wasForgotten()) return;
          const propTypeNode = prop.getTypeNode();
          if (propTypeNode && !propTypeNode.wasForgotten() &&
            (Node.isTypeLiteral(propTypeNode) || Node.isTypeReference(propTypeNode))) {
            count += self.processNestedProperties(propTypeNode, typeName, config);
          }
        });
      } else if (Node.isTypeReference(node)) {
        const typeArgs = node.getTypeArguments();
        typeArgs.forEach(arg => {
          if (!arg.wasForgotten()) {
            count += self.processNestedProperties(arg, typeName, config);
          }
        });
      }
      return count;
    },

    extractProperties: (decl: any): PropertySignature[] => {
      switch (true) {
        case Node.isTypeAliasDeclaration(decl): {
          const typeNode = decl.getTypeNode();
          return (typeNode && Node.isTypeLiteral(typeNode))
            ? typeNode.getProperties().filter(Node.isPropertySignature)
            : [];
        }
        case Node.isInterfaceDeclaration(decl):
          return decl.getProperties().filter(Node.isPropertySignature);
        default:
          return [];
      }
    },

    processDeclaration: (
      decl: any,
      config: Config,
      stats: ProcessingStats
    ): void => {
      const name = decl.getName();
      if (!name || !self.matchesPattern(name, self.getTargetPatterns(config))) return;

      // Handle nested declarations in namespaces
      if (Node.isModuleDeclaration(decl)) {
        const body = decl.getBody();
        if (body && Node.isModuleBlock(body)) {
          const statements = body.getStatements();
          statements.forEach(statement => {
            if (Node.isTypeAliasDeclaration(statement) || Node.isInterfaceDeclaration(statement)) {
              self.processDeclaration(statement, config, stats);
            }
          });
        }
        return;
      }

      const properties = self.extractProperties(decl);
      if (properties.length === 0) return;

      const boundShouldProcessProperty = (prop: PropertySignature, typeName: string) =>
        self.shouldProcessProperty(prop, typeName, config);

      const modifiedCount = self.processProperties(properties, name, config, boundShouldProcessProperty);
      if (modifiedCount > 0) {
        stats.typesModified++;
        stats.fieldsModified += modifiedCount;
      }

      properties
        .filter(prop => !prop.wasForgotten())
        .forEach(prop => {
          const typeNode = prop.getTypeNode();
          if (typeNode && !typeNode.wasForgotten() &&
            (Node.isTypeLiteral(typeNode) || Node.isTypeReference(typeNode))) {
            self.processNestedProperties(typeNode, name, config);
          }
        });
    },

    processAst: async (
      file: string,
      config: Config,
      stats: ProcessingStats,
      logger: { info: (msg: string) => void, warn: (msg: string) => void }
    ) => {
      try {
        const sourceFile = self.createProject().addSourceFileAtPath(file);
        const outputPath = join(config.outputDir, basename(file));
        const relativeOutputPath = outputPath.replace(process.cwd() + '/', '');

        if (!stats.processedFiles) {
          stats.processedFiles = new Set();
        }

        if (!stats.processedFiles.has(file)) {
          stats.processedFiles.add(file);
          logger.info(`ðŸ“ Output: ${relativeOutputPath}`);

          [
            ...sourceFile.getTypeAliases(),
            ...sourceFile.getInterfaces(),
            ...sourceFile.getModules()
          ].forEach(decl => self.processDeclaration(decl, config, stats));

          // Write the file in chunks if it's large
          const content = sourceFile.getFullText();
          await Bun.write(outputPath, content);

          stats.filesProcessed++;

          if (config.deleteOriginFile) {
            try {
              await unlink(file);
            } catch (error) {
              logger.warn(`Failed to delete original file: ${file}`);
            }
          }

          // Signal completion
          return true;
        }
        return false;
      } catch (error) {
        logger.warn(`Error processing file ${file}: ${error}`);
        return false;
      }
    }
  });

const self = astService.processorService;
```

```ts prisma-field-omitter/src/modules/config.service.ts
import Alvamind, { AlvamindInstance } from 'alvamind';
import { mkdirSync } from 'fs';
import { resolve } from 'path';
import type { Config } from '../types';
import { validationService } from './validation.service';

// Added explicit type annotation to satisfy TS2742
export const configService: AlvamindInstance = Alvamind({ name: 'config.service' })
  .use(validationService)
  .decorate('configService', {
    async readConfig(configPath: string): Promise<Config> {
      if (!configPath) {
        throw new Error('Config path is required');
      }

      const file = Bun.file(configPath);
      if (!await file.exists()) {
        throw new Error(`Config file not found: ${configPath}`);
      }

      const config = await file.json() as Config;

      const validationErrors = validationService.validationService.validateConfig(config);
      if (validationErrors.length > 0) {
        throw new Error(validationErrors.join('\n'));
      }

      const outputDir = resolve(process.cwd(), config.outputDir);
      mkdirSync(outputDir, { recursive: true });
      config.outputDir = outputDir;

      return config;
    }
  });
```

```ts prisma-field-omitter/src/modules/logger.service.ts
import Alvamind from 'alvamind';
import chalk from 'chalk';

export const loggerService = Alvamind({ name: 'logger.service' })
    .decorate('loggerService', {
        info: (message: string) => console.log(chalk.blue(message)),
        error: (message: string, error?: unknown) => {
            console.error(chalk.red(message));
            if (error) console.error(chalk.red(String(error)));
        },
        warn: (message: string) => console.warn(chalk.yellow(message)),
        success: (message: string) => console.log(chalk.green(message))
    });
```

```ts prisma-field-omitter/src/modules/processor.controller.ts
import Alvamind, { AlvamindInstance } from 'alvamind';
import { astService } from './ast.service';
import { progressService } from './progress.service';
import { statsService, type ProcessingStats } from './stats.service';
import { validationService } from './validation.service';
import { loggerService } from './logger.service';
import { regexService } from './regex.service';
import type { Config, ProcessingMode } from '../types';

export const processorController: AlvamindInstance = Alvamind({ name: 'processor.controller' })
  .use(astService)
  .use(progressService)
  .use(statsService)
  .use(validationService)
  .use(loggerService)
  .use(regexService)
  .derive(({
    astService: { getInputFiles, processAst },
    progressService: { create },
    statsService: { createStats },
    validationService: { validateConfig },
    loggerService: { info, warn },
    regexService: { processRegex } }) => ({

      process: async (config: Config, mode: ProcessingMode = 'ast'): Promise<ProcessingStats> => {
        const validationErrors = validateConfig(config);
        if (validationErrors.length > 0) {
          throw new Error('Configuration validation failed:\n' + validationErrors.join('\n'));
        }

        const stats = createStats();

        const files = (await getInputFiles(Array.isArray(config.originFile)
          ? config.originFile
          : [config.originFile]))
          .filter(file => !file.includes(config.outputDir));

        if (files.length === 0) {
          warn('No input files found matching the specified patterns');
          return stats;
        }

        const progress = create(files);
        info('Processing files:\n');

        const processFile = mode === 'ast' ? processAst : processRegex;

        for (const file of files) {
          // Update progress at start of file processing
          progress.updateProgress(file, 0);

          await new Promise(resolve => setTimeout(resolve, 10)); // Small delay for UI update

          const processed = await processFile(file, config, stats, {
            info: (msg) => {
              info(msg);
              // Ensure progress is displayed after log messages
              progress.updateProgress(file, 0.5);
            },
            warn
          });

          if (processed) {
            progress.updateProgress(file, 1);
            await new Promise(resolve => setTimeout(resolve, 10)); // Small delay for UI update
          }
        }

        progress.clear();
        info('\nâœ¨ Processing completed:');
        info(`ðŸ“ Files processed: ${stats.filesProcessed}`);
        info(`ðŸ”„ Types modified: ${stats.typesModified}`);
        info(`ðŸŽ¯ Fields modified: ${stats.fieldsModified}\n`);

        return stats;
      }
    }));
```

```ts prisma-field-omitter/src/modules/progress.service.ts
import Alvamind from 'alvamind';
import { statSync } from 'fs';

// State maintained outside of service with more tracking details
const state = {
    processedFiles: 0,
    lastLineLength: 0,
    currentFile: '',
    totalFiles: 0,
    totalBytes: 0
};

export const progressService = Alvamind({ name: 'progress.service' })
    .decorate('progressService', {
        create: (files: string[]) => {
            const width = 40;

            // Reset state for new batch
            state.processedFiles = 0;
            state.lastLineLength = 0;
            state.currentFile = '';
            state.totalFiles = files.length;
            state.totalBytes = files.reduce((acc, file) => {
                try {
                    return acc + statSync(file).size;
                } catch (error) {
                    return acc;
                }
            }, 0);

            const formatBytes = (bytes: number): string => {
                const units = ['B', 'KB', 'MB', 'GB'];
                let size = bytes;
                let unitIndex = 0;
                while (size >= 1024 && unitIndex < units.length - 1) {
                    size /= 1024;
                    unitIndex++;
                }
                return `${size.toFixed(1)}${units[unitIndex]}`;
            };

            return {
                updateProgress: (currentFile: string, fileProgress: number = 1) => {
                    state.currentFile = currentFile;

                    if (fileProgress === 1) {
                        state.processedFiles++;
                    }

                    try {
                        const percentage = Math.min(100, Math.round((state.processedFiles / state.totalFiles) * 100));
                        const filled = Math.round((width * state.processedFiles) / state.totalFiles);
                        const bar = 'â–ˆ'.repeat(filled) + 'â–‘'.repeat(width - filled);
                        const progress = `${state.processedFiles}/${state.totalFiles} files (${formatBytes(state.totalBytes)} total)`;
                        const line = `[${bar}] ${percentage}% ${progress}`;

                        // Clear previous line and write new progress
                        process.stdout.write('\r' + ' '.repeat(state.lastLineLength));
                        process.stdout.write('\r' + line);
                        // Add newline character to force immediate display
                        process.stdout.write('');

                        state.lastLineLength = line.length;
                    } catch (error) {
                        // Silent fail for progress display issues
                    }
                },

                clear: () => {
                    if (state.lastLineLength) {
                        process.stdout.write('\r' + ' '.repeat(state.lastLineLength) + '\r');
                        state.lastLineLength = 0;
                    }
                }
            };
        }
    });
```

```ts prisma-field-omitter/src/modules/regex.service.ts
import Alvamind from 'alvamind';
import type { Config } from '../types';
import type { ProcessingStats } from './stats.service';
import { basename, join } from 'path';
import { unlink } from 'fs/promises';

export const regexService = Alvamind({ name: 'regex.service' })
    .decorate('regexService', {
        createFieldPattern: (field: string | string[]): string => {
            const fields = Array.isArray(field) ? field : [field];
            return fields.map(f =>
                f.replace(/\*/g, '[\\w]+')
            ).join('|');
        },

        processContent: (content: string, config: Config): { content: string, modifications: number } => {
            let modifications = 0;
            let modifiedContent = content;

            for (const rule of config.hide) {
                const fieldPattern = self.createFieldPattern(rule.field);
                // Updated regex to match export type declarations and support namespaces
                const typeRegex = new RegExp(
                    `(^|\\n)(?!\\s*//\\s*)(\\s*)(${fieldPattern})\\s*:((\\s*[^;\\n]+(?:\\n(?!\\s*//\\s*)\\s*[^;\\n]+)*?));?`,
                    'gmi'
                );

                modifiedContent = modifiedContent.replace(regex, (match, newline, space, field, declaration) => {
                    modifications++;
                    if (config.action === 'delete') {
                        return newline; // Preserve the newline character
                    }

                    // Split matched declaration on semicolon for consecutive fields.
                    const parts = match.trim().split(/;\s*/).filter(Boolean);
                    return newline + parts.map(part =>
                        `${space}///// ${part.replace(/;$/, '').trim()};`
                    ).join('\n');
                });
            }

            return { content: modifiedContent, modifications };
        },

        processRegex: async (
            file: string,
            config: Config,
            stats: ProcessingStats,
            logger: { info: (msg: string) => void }
        ): Promise<boolean> => {
            try {
                const content = await Bun.file(file).text();
                const { content: processedContent, modifications } = self.processContent(content, config);

                if (modifications > 0) {
                    const outputPath = join(config.outputDir, basename(file));
                    await Bun.write(outputPath, processedContent);

                    if (config.deleteOriginFile) {
                        await unlink(file);
                    }

                    stats.filesProcessed++;
                    stats.fieldsModified += modifications;
                    logger.info(`ðŸ“ Processed: ${file} (${modifications} modifications)`);
                    return true;
                }

                return false;
            } catch (error) {
                console.error(`Error processing file ${file}:`, error);
                return false;
            }
        }
    });

const self = regexService.regexService;
```

```ts prisma-field-omitter/src/modules/stats.service.ts
import Alvamind from 'alvamind';

export interface ProcessingStats {
    filesProcessed: number;
    typesModified: number;
    fieldsModified: number;
    processedFiles?: Set<string>;
}

export const statsService = Alvamind({ name: 'stats.service' })
    .decorate('statsService', {
        createStats: (): ProcessingStats => ({
            filesProcessed: 0,
            typesModified: 0,
            fieldsModified: 0,
            processedFiles: new Set()
        })
    });
```

```ts prisma-field-omitter/src/modules/validation.service.ts
import Alvamind from 'alvamind';
import type { Config } from '../types';
import schema from '../prisma-field-omitter.schema.json';

export const validationService = Alvamind({ name: 'validation.service' })
    .decorate('validationService', {
        isValidOriginFile(value: unknown): boolean {
            if (typeof value === 'string') return true;
            if (Array.isArray(value)) return value.every(item => typeof item === 'string');
            return false;
        },

        isValidTarget(value: unknown): boolean {
            if (typeof value === 'string') return true;
            if (Array.isArray(value)) return value.every(item => typeof item === 'string');
            return false;
        },

        validateConfig(config: Config): string[] {
            const errors: string[] = [];

            // Required fields validation
            for (const field of schema.required) {
                const value = config[field as keyof Config];
                if (value === undefined || value === null) {
                    errors.push(`Missing required field: ${field}`);
                }
            }

            // Validate originFile format
            if (config.originFile && !self.isValidOriginFile(config.originFile)) {
                errors.push("originFile must be a string or array of strings");
            }

            // Validate hide rules
            if (config.hide?.length > 0) {
                config.hide.forEach((rule, index) => {
                    // Check required fields first
                    if (!rule.field) {
                        errors.push(`Hide rule #${index + 1}: Missing required field field`);
                        return;
                    }

                    // Validate field format only if it exists
                    if (rule.field && (typeof rule.field !== 'string' && !Array.isArray(rule.field))) {
                        errors.push(`Hide rule #${index + 1}: field must be a string or array of strings`);
                    }

                    // Validate target format
                    if (rule.target && !self.isValidTarget(rule.target)) {
                        errors.push(`Hide rule #${index + 1}: target must be a string pattern or array of patterns`);
                    }

                    // Validate on enum
                    if (rule.on && !schema.properties.hide.items.properties.on.enum.includes(rule.on)) {
                        errors.push(`Hide rule #${index + 1}: Invalid 'on' value. Must be ${schema.properties.hide.items.properties.on.enum.join(', ')}`);
                    }
                });
            }

            // Validate action enum
            if (config.action && !schema.properties.action.enum.includes(config.action)) {
                errors.push(`Invalid action value. Must be ${schema.properties.action.enum.join(' or ')}`);
            }

            // Validate generateOmitTypes and its path
            if (config.generateOmitTypes && !config.generatedOmitTypesOutputPath) {
                errors.push("generatedOmitTypesOutputPath is required when generateOmitTypes is true");
            }

            return errors;
        }
    });

const self = validationService.validationService;
```


```json prisma-field-omitter/src/prisma-field-omitter.schema.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "originFile": {
      "oneOf": [
        {
          "type": "string",
          "description": "Glob pattern matching input TypeScript files to process"
        },
        {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "Array of glob patterns matching input TypeScript files"
        }
      ]
    },
    "outputDir": {
      "type": "string",
      "description": "Directory where processed files will be written"
    },
    "deleteOriginFile": {
      "type": "boolean",
      "description": "If set to true, will delete the original input file after processing. Use with caution.",
      "default": false
    },
    "action": {
      "type": "string",
      "enum": [
        "comment",
        "delete"
      ],
      "description": "Specifies how to handle hidden fields - either comment them out with // or remove them completely",
      "default": "comment"
    },
    "generateOmitTypes": {
      "type": "boolean",
      "description": "When true, generates TypeScript types that omit the hidden fields from the original types",
      "default": false
    },
    "generatedOmitTypesOutputPath": {
      "type": "string",
      "description": "File path where the generated TypeScript types that omit hidden fields will be written"
    },
    "hide": {
      "type": "array",
      "description": "Array of configurations specifying which fields to hide and where to hide them",
      "items": {
        "type": "object",
        "properties": {
          "field": {
            "oneOf": [
              {
                "type": "string",
                "description": "A single field name or pattern (e.g. '*At' matches createdAt, updatedAt)"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Array of field names or patterns to hide"
              }
            ],
            "description": "Specifies which field(s) should be hidden - can be exact names or glob patterns"
          },
          "target": {
            "oneOf": [
              {
                "type": "string",
                "enum": [
                  "all"
                ],
                "description": "Apply to all possible targets"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Array of glob patterns matching type names where fields should be hidden"
              }
            ],
            "description": "Specifies which Prisma types the hiding should be applied to"
          },
          "on": {
            "type": "string",
            "enum": [
              "input",
              "output",
              "both"
            ],
            "description": "Whether to hide fields on input types, output types, or both",
            "default": "both"
          }
        },
        "required": [
          "field"
        ],
        "additionalProperties": false
      }
    }
  },
  "required": [
    "originFile",
    "outputDir",
    "hide"
  ],
  "additionalProperties": false
}
```

```ts prisma-field-omitter/src/types.d.ts
declare module "*.json" {
    const content: any;
    export default content;
}
```

```ts prisma-field-omitter/src/types.ts
export interface HideRule {
    field: string | string[];
    target?: "all" | string[];
    on?: "input" | "output" | "both";
}

export interface Config {
    originFile: string | string[];
    outputDir: string;
    deleteOriginFile?: boolean;
    action?: "comment" | "delete";
    generateOmitTypes?: boolean;
    generatedOmitTypesOutputPath?: string;
    hide: HideRule[];
    [key: string]: unknown;
}

export type ProcessingMode = 'ast' | 'regex';

export interface ProcessingOptions {
    configPath: string;
    parallel?: number;
    verbose?: boolean;
    mode?: ProcessingMode;
}
```




This is a TypeScript project that creates a utility for omitting/hiding fields from Prisma-generated TypeScript types. Here's a breakdown of the key components:

Key Features:
1. Field Omission: Can hide fields from Prisma-generated types either by commenting them out or deleting them
2. Pattern Matching: Supports glob patterns for matching files and fields
3. Processing Modes: Offers both AST-based and regex-based processing
4. Progress Tracking: Shows real-time progress during processing
5. Configuration: Uses JSON schema for config validation

Core Components:

1. CLI Entry Point (`cli.ts`):
```typescript
export async function run(options: ProcessingOptions) {
  // Handles CLI execution and options parsing
  // Uses --config and --mode flags
}
```

2. Services:

- `ast.service.ts`: Handles AST-based processing using ts-morph
```typescript
processAst: async (file: string, config: Config, stats: ProcessingStats) => {
  // Processes TypeScript files by manipulating their AST
}
```

- `regex.service.ts`: Handles regex-based processing
```typescript
processRegex: async (file: string, config: Config, stats: ProcessingStats) => {
  // Processes files using regex patterns
}
```

- `config.service.ts`: Configuration management
```typescript
readConfig(configPath: string): Promise<Config> {
  // Reads and validates configuration
}
```

3. Configuration Schema:
```json
{
  "originFile": "string | string[]",  // Input files to process
  "outputDir": "string",              // Output directory
  "hide": [{                          // Rules for hiding fields
    "field": "string | string[]",     // Fields to hide
    "target": "all | string[]",       // Where to apply hiding
    "on": "input | output | both"     // Type of definitions to affect
  }]
}
```

Usage Example:
```json
{
  "originFile": "./prisma/generated/*.ts",
  "outputDir": "./generated",
  "hide": [
    {
      "field": ["password", "secret*"],
      "target": ["User*"],
      "on": "output"
    }
  ]
}
```

Command Line:
```bash
prisma-field-omitter --config ./config.json --mode ast
```

The project uses Bun as the runtime and leverages modern TypeScript features. It's well-structured with separation of concerns and modular design using the Alvamind framework for dependency injection and service management.

Key Patterns:
1. Service-based architecture
2. Dependency injection
3. Progressive enhancement (AST/regex modes)
4. Configuration validation
5. Progress monitoring
6. Error handling

Would you like me to explain any specific part in more detail?

I want EnhancerGenerator to directly omit fields during the Prisma Client generation, based on a configuration file similar to prisma-field-omitter, rather than post-processing the generated files. This is a much more efficient approach

Yes, integrating field omission directly into the EnhancerGenerator would be more efficient than post-processing. Here's how we can modify the EnhancerGenerator to support field omission during generation:

1. First, let's add the configuration types:

```typescript
// src/plugins/enhancer/types.ts
export interface OmitConfig {
  fields: FieldOmitRule[];
}

export interface FieldOmitRule {
  field: string | string[];  // Field name or pattern
  target?: string | string[];  // Target model/type name pattern
  on?: 'input' | 'output' | 'both';  // Default to 'both'
}
```

2. Then modify the EnhancerGenerator to handle field omission:

```typescript
// src/plugins/enhancer/enhance/index.ts
export class EnhancerGenerator {
    private readonly omitConfig?: OmitConfig;

    constructor(
        private readonly model: Model,
        private readonly options: PluginOptions,
        private readonly project: Project,
        private readonly outDir: string
    ) {
        // Load omit configuration if provided
        this.omitConfig = this.loadOmitConfig();
    }

    private loadOmitConfig(): OmitConfig | undefined {
        const configPath = this.options.omitConfigPath;
        if (!configPath) return undefined;

        try {
            const config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
            return this.validateOmitConfig(config);
        } catch (error) {
            throw new PluginError(name, `Failed to load omit configuration: ${error}`);
        }
    }

    private validateOmitConfig(config: any): OmitConfig {
        // Add validation logic here
        return config;
    }

    private shouldOmitField(fieldName: string, typeName: string, isInput: boolean): boolean {
        if (!this.omitConfig) return false;

        return this.omitConfig.fields.some(rule => {
            // Check field name match
            const fieldPattern = Array.isArray(rule.field) ? rule.field : [rule.field];
            const fieldMatches = fieldPattern.some(pattern =>
                new RegExp(`^${pattern.replace(/\*/g, '.*')}$`).test(fieldName)
            );
            if (!fieldMatches) return false;

            // Check target match if specified
            if (rule.target) {
                const targetPattern = Array.isArray(rule.target) ? rule.target : [rule.target];
                const targetMatches = targetPattern.some(pattern =>
                    new RegExp(`^${pattern.replace(/\*/g, '.*')}$`).test(typeName)
                );
                if (!targetMatches) return false;
            }

            // Check input/output rule
            const on = rule.on || 'both';
            return on === 'both' || (isInput && on === 'input') || (!isInput && on === 'output');
        });
    }

    private processTypeNode(node: InterfaceDeclaration | TypeAliasDeclaration): void {
        const typeName = node.getName();
        const isInput = typeName.includes('Input');

        // Handle properties in type literals
        const properties = node.getProperties();
        for (const prop of properties) {
            if (this.shouldOmitField(prop.getName(), typeName, isInput)) {
                prop.remove();
            }
        }

        // Handle nested types
        node.forEachDescendant(child => {
            if (Node.isTypeLiteral(child)) {
                const properties = child.getProperties();
                for (const prop of properties) {
                    if (this.shouldOmitField(prop.getName(), typeName, isInput)) {
                        prop.remove();
                    }
                }
            }
        });
    }

    async generate(): Promise<{ dmmf: DMMF.Document | undefined; newPrismaClientDtsPath: string | undefined }> {
        let dmmf: DMMF.Document | undefined;

        // Generate logical client if needed
        if (this.needsLogicalClient) {
            const result = await this.generateLogicalPrisma();
            dmmf = result.dmmf;

            // Process generated types to omit fields
            if (this.omitConfig) {
                const clientDtsPath = path.join(this.outDir, LOGICAL_CLIENT_GENERATION_PATH, 'index.d.ts');
                const sourceFile = this.project.getSourceFileOrThrow(clientDtsPath);

                // Process all type aliases and interfaces
                sourceFile.getTypeAliases().forEach(type => this.processTypeNode(type));
                sourceFile.getInterfaces().forEach(iface => this.processTypeNode(iface));

                await sourceFile.save();
            }
        }

        // Rest of the generate method...
        return { dmmf, newPrismaClientDtsPath: undefined };
    }

    // ... rest of the class
}
```

3. Update the plugin options to include omit configuration:

```typescript
// src/plugins/enhancer/types.ts
export interface EnhancerPluginOptions extends PluginOptions {
    omitConfigPath?: string;
}
```

Usage example:

```json
// omit-config.json
{
  "fields": [
    {
      "field": ["password", "secret*"],
      "target": ["User*"],
      "on": "output"
    },
    {
      "field": "internalId",
      "target": "all",
      "on": "both"
    }
  ]
}
```

```prisma
// schema.prisma
generator client {
  provider = "prisma-client-js"
}

generator zmodel {
  provider = "zenstack"
  output = "generated"
  omitConfig = "./omit-config.json"  // Reference omit configuration
}
```

This approach:

1. Processes field omission during type generation rather than after
2. Uses the same pattern matching capabilities as prisma-field-omitter
3. Integrates directly with the existing EnhancerGenerator
4. Supports both input and output type modifications
5. Handles nested types and complex patterns
6. Maintains type safety through the entire process

The main benefits over post-processing:
- More efficient (single-pass processing)
- More reliable (works with the AST during generation)
- Better integration with the rest of ZenStack
- Cleaner output files (no commented code)
- Proper handling of type dependencies

Would you like me to explain any specific part in more detail?

are you sure?

Yesâ€”integrating field omission directly into the generation process (as opposed to postâ€‘processing generated files) is not only possible but can be more efficient and robust. The idea is to modify the EnhancerGenerator so that, as it builds and transforms the Prisma client type AST, it consults an omission configuration (similar to your prismaâ€‘fieldâ€‘omitter) and removes the matching fields immediately. This way, the final generated file is already â€œcleanâ€ and you donâ€™t need an extra pass over the full text.

A few points to be sure about:

1. The omission configuration (for example, in JSON) specifies which fields (using literal names or glob patterns) should be omitted, on which target types (input, output, or both).

2. When the EnhancerGenerator processes each type (interfaces or type aliases), you can use tsâ€‘morph to walk the AST. For every property signature (or nested type literal) that is encountered, you test if it matches one of your omission rules. If it does, you remove it from the AST before saving the file.

3. Because you're working at the AST level, you avoid potential pitfalls of regexâ€‘based manipulation (for example, accidentally removing comments or unrelated code).

4. The integration can run as part of the same pass that fixes other type issues (such as delegate adjustments and authâ€‘related modifications). This keeps everything in one place and is more maintainable.

The code sample provided in the previous message illustrates this concept by:

â€¢ Reading a configuration file from a provided path (added as an option on the plugin)

â€¢ Adding helper functions to check whether a field (given its name, the type it belongs to, and the kind of typeâ€”input or output) should be omitted

â€¢ Modifying the type declarations and nested type literals accordingly before final output

In short, yesâ€”Iâ€™m sure this approach is both technically sound and likely to offer better performance and cleaner output compared to file postâ€‘processing. Of course, as with any integration that touches AST transformation, you should test it on some representative schemas to ensure that edge cases (like nested types, conditional types, or inferred properties) are handled as expected.

why do we even need ast processing when we dont do post processing, we do direct generating comparing, why not simple regex and string manipulation?

You're absolutely right! When we're generating the types directly (not post-processing), we don't need AST manipulation at all. We can simply use pattern matching and string manipulation since we're working with the DMMF (Prisma's internal model) during the generation phase.

Here's a simpler approach:

```typescript
// src/plugins/enhancer/enhance/index.ts
export class EnhancerGenerator {
    private readonly omitConfig?: OmitConfig;

    constructor(
        private readonly model: Model,
        private readonly options: PluginOptions,
        private readonly project: Project,
        private readonly outDir: string
    ) {
        this.omitConfig = this.loadOmitConfig();
    }

    private loadOmitConfig(): OmitConfig | undefined {
        const configPath = this.options.omitConfigPath;
        if (!configPath) return undefined;

        try {
            const config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
            return this.validateOmitConfig(config);
        } catch (error) {
            throw new PluginError(name, `Failed to load omit configuration: ${error}`);
        }
    }

    private shouldOmitField(fieldName: string, typeName: string, isInput: boolean): boolean {
        if (!this.omitConfig) return false;

        return this.omitConfig.fields.some(rule => {
            // Check field name match using glob patterns
            const fields = Array.isArray(rule.field) ? rule.field : [rule.field];
            const fieldMatches = fields.some(pattern =>
                new Glob(pattern).match(fieldName)
            );
            if (!fieldMatches) return false;

            // Check target type match
            if (rule.target && rule.target !== 'all') {
                const targets = Array.isArray(rule.target) ? rule.target : [rule.target];
                const targetMatches = targets.some(pattern =>
                    new Glob(pattern).match(typeName)
                );
                if (!targetMatches) return false;
            }

            // Check input/output rule
            const on = rule.on || 'both';
            return on === 'both' || (isInput && on === 'input') || (!isInput && on === 'output');
        });
    }

    async generate(): Promise<{ dmmf: DMMF.Document | undefined; newPrismaClientDtsPath: string | undefined }> {
        if (!this.needsLogicalClient) {
            return { dmmf: undefined, newPrismaClientDtsPath: undefined };
        }

        // Generate logical prisma schema
        const result = await this.generateLogicalPrisma();
        let dmmf = result.dmmf;

        // If we have omit config, filter the DMMF
        if (this.omitConfig && dmmf) {
            // Filter input types
            dmmf.schema.inputObjectTypes.prisma = dmmf.schema.inputObjectTypes.prisma
                .map(type => ({
                    ...type,
                    fields: type.fields.filter(field =>
                        !this.shouldOmitField(field.name, type.name, true)
                    )
                }));

            // Filter output types
            dmmf.schema.outputObjectTypes.prisma = dmmf.schema.outputObjectTypes.prisma
                .map(type => ({
                    ...type,
                    fields: type.fields.filter(field =>
                        !this.shouldOmitField(field.name, type.name, false)
                    )
                }));
        }

        // Rest of generation process...
        return { dmmf, newPrismaClientDtsPath: undefined };
    }
}

interface OmitConfig {
    fields: Array<{
        field: string | string[];     // Field name or pattern
        target?: 'all' | string[];    // Target model/type patterns
        on?: 'input' | 'output' | 'both';
    }>;
}
```

Key differences from the previous approach:

1. Works directly with DMMF instead of AST processing
2. Uses simple pattern matching with glob
3. Filters fields during the generation phase
4. No need for complex AST traversal or manipulation
5. Much simpler implementation

Example config remains the same:

```json
{
    "fields": [
        {
            "field": ["password", "secret*"],
            "target": ["User*"],
            "on": "output"
        },
        {
            "field": "internalId",
            "target": "all",
            "on": "both"
        }
    ]
}
```

This approach is:
- Simpler
- More performant
- Easier to maintain
- More reliable since it works at the DMMF level
- Integrates naturally with Prisma's type generation

Thank you for the correction! Sometimes simpler is better, and in this case working directly with DMMF during generation is clearly the better approach than complex AST manipulation.
